import fs from 'fs';
import path from 'path';
import axios from 'axios';
import 'dotenv/config'; // è‡ªå‹•è®€å–æ ¹ç›®éŒ„ .env

const GROQ_API_KEY = process.env.GROQ_API_KEY;
const GROQ_MODEL = process.env.GROQ_MODEL || "llama-3.3-70b-versatile";
const GROQ_EMBED_MODEL = process.env.GROQ_EMBED_MODEL || "nomic-embed-text-v2"; // æ–°å¢

// Vercel ä¸Šæ²’æœ‰ __dirnameï¼Œè¦ç”¨ process.cwd()
const ROOT_DIR = process.cwd();
const CACHE_PATH = path.join(ROOT_DIR, 'lib/supabase_embeddings.json');
const SUPABASE_FETCH = path.join(ROOT_DIR, 'lib/supabase_fetch.js');

// å¯é¸è‡ªå‹•åŒæ­¥
const USE_AUTO_SYNC = process.env.USE_AUTO_SYNC === 'true';
if (USE_AUTO_SYNC) {
  import('./supabase_auto_sync.js').then(mod => {
    mod.startAutoSync()
      .then(() => console.log('âœ… è‡ªå‹•åŒæ­¥å·²å•Ÿå‹•'))
      .catch(err => console.error('âŒ è‡ªå‹•åŒæ­¥å•Ÿå‹•å¤±æ•—:', err));
  });
}

// åˆå§‹å¿«å–æª¢æŸ¥
if (!fs.existsSync(CACHE_PATH)) {
  console.log('âš ï¸ å¿«å–ä¸å­˜åœ¨, åŸ·è¡Œåˆå§‹è¼‰å…¥...');
  import('./supabase_fetch.js').then(mod => mod.default());
} else {
  console.log('âœ… ä½¿ç”¨ç¾æœ‰å¿«å–');
}

/* ---------------------------------------------------
 *  æ–¹æ¡ˆ Aï¼šä½¿ç”¨ Groq Embedding APIï¼ˆå–ä»£ Pythonï¼‰
 * --------------------------------------------------- */
export async function getEmbedding(text) {
  try {
    const response = await axios.post(
      "https://api.groq.com/openai/v1/embeddings",
      {
        model: GROQ_EMBED_MODEL,
        input: text,
      },
      {
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
        },
      }
    );

    const embedding =
      response?.data?.data?.[0]?.embedding || null;

    if (!embedding) {
      console.error("âŒ Groq embedding API ç„¡å›å‚³è³‡æ–™:", response.data);
      return null;
    }

    return embedding;
  } catch (err) {
    console.error("âŒ Groq embedding API éŒ¯èª¤:", err.response?.data || err);
    return null;
  }
}

/* ---------------------------------------------------
 *  ä¸»è¦ QA æµç¨‹
 * --------------------------------------------------- */
export async function generateAnswer(query) {
  console.log("ğŸ” æ­£åœ¨ç”¢ç”Ÿ embedding:", query);

  const queryEmbedding = await getEmbedding(query);
  if (!queryEmbedding) {
    console.error('æŸ¥è©¢å‘é‡ç”Ÿæˆå¤±æ•—');
    return 'æŸ¥è©¢å¤±æ•—ï¼ˆembedding å¤±æ•—ï¼‰';
  }

  // è®€å–å¿«å–
  if (!fs.existsSync(CACHE_PATH)) {
    return "æ‰¾ä¸åˆ° supabase_embeddings.jsonï¼Œè«‹å…ˆåŸ·è¡Œ supabase_fetch.js";
  }

  let cache = {};
  try {
    cache = JSON.parse(fs.readFileSync(CACHE_PATH, 'utf-8'));
  } catch {
    return "supabase_embeddings.json è§£æå¤±æ•—";
  }

  const contextChunks = Object.values(cache);
  if (contextChunks.length === 0) {
    return "embedding å¿«å–ç‚ºç©º";
  }

  /* ----------------------------
   *  Cosine Similarity
   * ---------------------------- */
  function cosineSimilarity(a, b) {
    const dot = a.reduce((sum, v, i) => sum + v * b[i], 0);
    const normA = Math.sqrt(a.reduce((sum, v) => sum + v * v, 0));
    const normB = Math.sqrt(b.reduce((sum, v) => sum + v * v, 0));
    return dot / (normA * normB);
  }

  const scored = contextChunks.map(chunk => ({
    chunk,
    sim: cosineSimilarity(queryEmbedding, chunk.embedding),
  }));

  scored.sort((a, b) => b.sim - a.sim);
  const top3 = scored.slice(0, 3);

  console.log("ğŸ“Œ æŸ¥è©¢ç›¸ä¼¼åº¦å‰ 3ï¼š");
  top3.forEach((item, idx) => {
    console.log(`#${idx + 1} sim=${item.sim}`);
    console.log(item.chunk.content);
    console.log("------------------------------");
  });

  let mostRelevantChunk = top3[0].chunk;
  const maxSim = top3[0].sim;

  /* ---------------------------------------------------
   *  Fallbackï¼šé—œéµå­—æ¯”å°
   * --------------------------------------------------- */
  if (maxSim < 0.9) {
    const words = query.match(/[\u4e00-\u9fa5]|\w+/g) || [];

    // ç”¢ç”Ÿ uni-gram / bi-gram / tri-gram
    const ngrams = [];
    for (let n = 1; n <= 3; n++) {
      for (let i = 0; i <= words.length - n; i++) {
        ngrams.push(words.slice(i, i + n).join(''));
      }
    }

    const keywordSet = new Set(ngrams);
    console.log("ğŸ” fallback é—œéµå­—ï¼š", [...keywordSet]);

    const fallbackChunks = contextChunks.filter(chunk =>
      [...keywordSet].some(kw => chunk.content.includes(kw))
    );

    if (fallbackChunks.length > 0) {
      let grouped = [];
      [...keywordSet].forEach(kw => {
        const hits = contextChunks.filter(c => c.content.includes(kw));
        if (hits.length > 0) {
          grouped.push(`ã€${kw}ã€‘\n` + hits.map(c => c.content).join("\n"));
        }
      });
      mostRelevantChunk = { content: grouped.join("\n---\n") };
    }
  }

  /* ---------------------------------------------------
   *  æœ€å¾Œï¼šå‘¼å« Groq LLM
   * --------------------------------------------------- */
  try {
    const response = await axios.post(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        model: GROQ_MODEL,
        messages: [
          {
            role: "system",
            content:
              "ä½ æ˜¯æª¢ç´¢å¢å¼·å‹åŠ©ç†ï¼Œå›ç­”ä¸€å¾‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œåªèƒ½æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”ï¼Œä¸å¯è£œå……æˆ–æ¨æ¸¬ä»»ä½•æœªåœ¨åƒè€ƒè³‡æ–™ä¸­çš„å…§å®¹ã€‚å³ä½¿ç›¸é—œåº¦ä½ï¼Œä¹Ÿè«‹æ ¹æ“šåƒè€ƒè³‡æ–™ç›¡é‡å›ç­”ã€‚",
          },
          {
            role: "user",
            content: `å•é¡Œï¼š${query}\n\nåƒè€ƒè³‡æ–™ï¼š${mostRelevantChunk.content}`,
          },
        ],
      },
      {
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
        },
      }
    );

    const answer = response.data?.choices?.[0]?.message?.content;
    return answer || "æŸ¥è©¢å¤±æ•—ï¼ˆGroq å›å‚³ç•°å¸¸ï¼‰";
  } catch (err) {
    console.error("Groq API éŒ¯èª¤:", err.response || err);
    return "æŸ¥è©¢å¤±æ•—ï¼ˆGroq API éŒ¯èª¤ï¼‰";
  }
}

/* ---------------------------------------------------
 *  æ¸¬è©¦æŸ¥è©¢
 * --------------------------------------------------- */
generateAnswer("å¯ä¸å¯ä»¥é¤Šå¯µç‰©?").then(console.log);
